{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separability and Hidden Layers\n",
    "\n",
    "The goal of this module is to demonstrate how a neural network makes data separable if it isn't already.\n",
    "\n",
    "You will:\n",
    "* become familiar with the basic functioning of a simple deep network\n",
    "* learn to view a network as a composition of functions\n",
    "* explore the concept of \"representation learning\"\n",
    "\n",
    "Much credit goes to [http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/](http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/) in inspiring these exercises. It is highly recommended reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We'll use our handy decision boundary plot function from last time\n",
    "def plot_decision_boundary(model, X, y):\n",
    "    X_max = X.max(axis=0)\n",
    "    X_min = X.min(axis=0)\n",
    "    xticks = np.linspace(X_min[0], X_max[0], 100)\n",
    "    yticks = np.linspace(X_min[1], X_max[1], 100)\n",
    "    xx, yy = np.meshgrid(xticks, yticks)\n",
    "    ZZ = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = ZZ[:,0] >= 0.5\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax = plt.gca()\n",
    "    ax.contourf(xx, yy, Z, cmap=plt.cm.bwr, alpha=0.2)\n",
    "    ax.scatter(X[:,0], X[:,1], c=y[:,0], alpha=0.4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Learning non-separable data\n",
    "\n",
    "Let's take a look at a more challenging dataset, one that is not linearly separable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs, make_circles\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_circles(n_samples=1000,\n",
    "                    noise=0.02,\n",
    "                    factor=0.3)\n",
    "y = np_utils.to_categorical(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1], c=y[:,0], alpha=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the model we build last time on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model0 = Sequential()\n",
    "model0.add(Dense(2, input_dim=2, activation='softmax'))\n",
    "\n",
    "model0.compile(loss='categorical_crossentropy',\n",
    "               optimizer=SGD(lr=0.04),\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "model0.fit(X_train, y_train, nb_epoch=20, batch_size=16)\n",
    "result = model0.evaluate(X_test, y_test)\n",
    "print 'Test set loss: ', result[0]\n",
    "print 'Test set accuracy: ', result[1]\n",
    "\n",
    "plot_decision_boundary(model0, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model doesn't do nearly as well, which is no surprise. The model isn't **expressive** enough to represent a more complicated decision boundary.\n",
    "\n",
    "- - - \n",
    "### Exercise 1 - the model's strategy\n",
    "\n",
    "Though our model doesn't have agency or a mind or it's own, it is a nice shorthand to talk about what the model is \"trying\" to do in a given situation. Based on the decision boundary plot, can you explain what the model's strategy is and why it gets the accuracy that it does? Try training the model a few times to see what other solutions it finds. Is there a solution that gives the best accuracy?\n",
    "- - -\n",
    "\n",
    "\n",
    "- - -\n",
    "### Exercise 2 - expressiveness and structure\n",
    "\n",
    "Recalling the structure of our model that you already sketched out, can you explain why this model can only make a linear decision boundary?\n",
    "- - -\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a hidden layer\n",
    "\n",
    "We can make our model more expressive by adding a hidden layer. As we will see, this expands the expressiveness and representational capacity of the model, giving it enough power to separate the data.\n",
    "\n",
    "- - -\n",
    "### Exercise 3 - add a hidden layer\n",
    "\n",
    "Below is the model specification we used already. Modify it in place to:\n",
    "\n",
    "1. make the first layer 3 dimensional rather than 2 dimensional\n",
    "2. add a \"relu\" `Activation` layer and a `Dense` layer that feeds into the last softmax layer. \n",
    "\n",
    "Hint: the `Dense` layer will not need to specify an `input_dim` since Keras will know the input dimension from the previous layer already.\n",
    "- - -\n",
    "\n",
    "<a id=\"compile\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Edit the model below to add new 3-dimensional hidden layer\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(2, input_dim=2)) # Change the hidden layer to be 3 dimensional\n",
    "# Add a 'relu' layer and Dense layer with an output of 2 dimensions\n",
    "model1.add(Activation('softmax'))\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "               optimizer=SGD(lr=0.04),\n",
    "               metrics=['accuracy'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4 - a more expressive structure\n",
    "\n",
    "From the summary, check that your new model 1) has the same input and output dimension as before and 2) has 17 parameters. \n",
    "\n",
    "Draw this new model. Is it clear where all of the parameters are?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model1.fit(X_train, y_train, nb_epoch=20, batch_size=16)\n",
    "plot_decision_boundary(model1, X, y)\n",
    "\n",
    "result = model1.evaluate(X_test, y_test)\n",
    "print 'Test set loss: ', result[0]\n",
    "print 'Test set accuracy: ', result[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your model should have done quite well. If not, you can reset and recompile the model (by running the cell where you defined the model) and train it again. Results vary from run to run, so train the network a few times to see how well it does (since we are not training the model very long, it might actually do quite badly on some of the runs). \n",
    "\n",
    "Retrain the model until you get a pretty high accuracy, then let's take a peak inside of the network to find out how this model can build a non-linear decision boundary.\n",
    "\n",
    "## Representation Learning: inspecting the output of the hidden layer\n",
    "\n",
    "When you added the hidden layer in the last model, you allowed the model to **re-represent** the input data before the final softmax decision layer. Let's take a look at this representation by looking at the activation of the units at the hidden layer. First, it is useful to know how to print out a model's layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model1.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to extract the activations at the hidden layer from Keras, we can [create a function](http://keras.io/getting-started/faq/#how-can-i-visualize-the-output-of-an-intermediate-layer) where we specify what layer we would like to \"extract\" the value of like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "get_hidden_layer_output = K.function([model1.layers[0].input],\n",
    "                                     [model1.layers[1].output])\n",
    "H = get_hidden_layer_output([X_test])[0]\n",
    "\n",
    "print H.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally, our data is 3-dimensional, which is the dimension of the hidden layer of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# A helper function to make a 3d scatter plot\n",
    "def plot_3d_representation(X, y):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(X[:,0], X[:,1], X[:,2], c=y[:,0], alpha=0.2)\n",
    "    ax.view_init(60, 30)\n",
    "\n",
    "plot_3d_representation(H, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you see? Are the classes linearly separable now? Discuss what you think is happening with a partner or instructor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding capacity\n",
    "\n",
    "We added a hidden layer with 3 dimensions, but we can give the model more capacity by using more dimensions. Maybe you noticed that the 3-dimensional model didn't always find a good solution on every run. Expanding the dimension of the hidden layer - giving the layer more representational capacity - should mostly fix that problem.\n",
    "\n",
    "### Exercise 5 - expanding the hidden layer\n",
    "\n",
    "Build a new model with a few more hidden units but is otherwise identical and train it on the circle data. How does this model perform compared to the previous model after training?\n",
    "\n",
    "What is different about the accuracy of the model over the course of training? Can your model get perfect accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define model2 here with the some more hidden units and train it on the circle data."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
